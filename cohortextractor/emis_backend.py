import csv
import datetime
import os
import re
import uuid
import warnings

import structlog

from .codelistlib import codelist
from .expressions import format_expression
from .presto_utils import presto_connection_from_url

logger = structlog.get_logger()

# Characters that are safe to interpolate into SQL (see
# `placeholders_and_params` below)
safe_punctation = r" _.-+/()"
SAFE_CHARS_RE = re.compile(f"^[a-zA-Z0-9{re.escape(safe_punctation)}]+$")


PATIENT_TABLE = "patient_all_orgs_v2"
MEDICATION_TABLE = "medication_all_orgs_v2"
OBSERVATION_TABLE = "observation_all_orgs_v2"
IMMUNISATIONS_TABLE = "immunisation_all_orgs_v2"
ICNARC_TABLE = "icnarc_view"
ONS_TABLE = "ons_view"
CPNS_TABLE = "cpns_view"


class EMISBackend:
    _db_connection = None
    _current_column_name = None

    def __init__(self, database_url, covariate_definitions, temporary_database=None):
        self.database_url = database_url
        self.covariate_definitions = covariate_definitions
        self.postprocess_covariate_definitions()
        self.codelist_tables = []
        self.temp_table_prefix = self.get_temp_table_prefix()
        self.queries = self.get_queries(self.covariate_definitions)
        logger.info(
            "Initialising EMISBackend", temp_table_prefix=self.temp_table_prefix
        )

    def postprocess_covariate_definitions(self):
        """The pseudo_id field is an integer in TPP and a string in EMIS.  It is defined
        as being an integer in process_covariate_definitions, so we override that here.
        """

        for name, (query_type, query_args) in self.covariate_definitions.items():
            if query_args.get("returning") == "pseudo_id":
                query_args["column_type"] = "str"

    def to_csv(self, filename):
        result = self.execute_query()
        unique_check = UniqueCheck()
        with open(filename, "w", newline="") as csvfile:
            writer = csv.writer(csvfile)
            writer.writerow([x[0] for x in result.description])
            for row in result:
                unique_check.add(row[0])
                writer.writerow(row)
        unique_check.assert_unique_ids()

    def to_dicts(self):
        result = self.execute_query()
        keys = [x[0] for x in result.description]
        # Convert all values to str as that's what will end in the CSV
        output = [dict(zip(keys, map(str, row))) for row in result]
        unique_check = UniqueCheck()
        for item in output:
            unique_check.add(item["patient_id"])
        unique_check.assert_unique_ids()
        return output

    def to_sql(self):
        """
        Generate a single SQL string.

        Useful for debugging, optimising, etc.
        """
        prepared_sql = ["-- Create codelist tables"]
        for sql in self.codelist_tables:
            prepared_sql.append(f"{sql};\n\n")
        for name, query in self.queries:
            prepared_sql.append(f"-- Query for {name}")
            prepared_sql.append(f"{query};\n\n")
        return "\n".join(prepared_sql)

    def get_queries(self, covariate_definitions):
        output_columns = {}
        column_types = {}
        is_hidden = {}
        table_queries = {}
        for name, (query_type, query_args) in covariate_definitions.items():
            # So we can safely mutate these below
            query_args = query_args.copy()
            # These arguments are not used in generating column data and the
            # corresponding functions do not accept them
            query_args.pop("return_expectations", None)
            is_hidden[name] = query_args.pop("hidden", False)
            column_type = query_args.pop("column_type")
            # Record the types of columns we've seen so far so that
            # `categorised_as` expressions can use them if necessary
            column_types[name] = column_type
            # `categorised_as` columns don't generate their own table query,
            # they're just a CASE expression over columns generated by other
            # queries
            if query_type == "categorised_as":
                output_columns[name] = self.get_case_expression(
                    column_types, output_columns, **query_args
                )
            # `value_from` columns also don't generate a table, they just take
            # a value from another table
            elif query_type == "value_from":
                assert query_args["source"] in table_queries
                output_columns[name] = self.get_column_expression(
                    column_type, **query_args
                )
            # As do `aggregate_of` columns
            elif query_type == "aggregate_of":
                output_columns[name] = self.get_aggregate_expression(
                    column_type, output_columns, **query_args
                )
            else:
                date_format_args = pop_keys_from_dict(query_args, ["date_format"])
                cols, sql = self.get_query(name, query_type, query_args)
                table_name = self.make_temp_table_name(name)
                table_queries[
                    name
                ] = f"CREATE TABLE IF NOT EXISTS {table_name} AS {sql}"
                # The first column should always be patient_id so we can join on it
                assert cols[0] == "patient_id"
                output_columns[name] = self.get_column_expression(
                    column_type, name, cols[1], **date_format_args
                )
        # If the population query defines its own temporary table then we use
        # that as the primary table to query against and left join everything
        # else against that. Otherwise, we use the `patient` table.
        if "population" in table_queries:
            primary_table = self.make_temp_table_name("population")
            patient_id_expr = f"{primary_table}.patient_id"
        else:
            primary_table = PATIENT_TABLE
            patient_id_expr = f"{PATIENT_TABLE}.registration_id"
        # Insert `patient_id` as the first column
        output_columns = dict(patient_id=patient_id_expr, **output_columns)
        output_columns_str = ",\n          ".join(
            f"{expr} AS {name}"
            for (name, expr) in output_columns.items()
            if not is_hidden.get(name) and name != "population"
        )
        output_columns_str += f",\n          {primary_table}.hashed_organisation"
        joins = []
        for name in table_queries:
            if name == "population":
                continue
            table_name = self.make_temp_table_name(name)
            joins.append(
                f"LEFT JOIN {table_name} ON {table_name}.patient_id = {patient_id_expr}"
            )
        joins_str = "\n          ".join(joins)
        joined_output_query = f"""
        SELECT
          {output_columns_str}
        FROM
          {primary_table}
          {joins_str}
        WHERE {output_columns["population"]} = 1
        """
        return list(table_queries.items()) + [("final_output", joined_output_query)]

    def get_column_expression(self, column_type, source, returning, date_format=None):
        default_value = self.get_default_value_for_type(column_type)
        table_name = self.make_temp_table_name(source)
        column_expr = f"{table_name}.{returning}"
        if column_type == "date":
            column_expr = truncate_date(column_expr, date_format)
        return f"COALESCE({column_expr}, {quote(default_value)})"

    def get_default_value_for_type(self, column_type):
        if column_type == "date":
            return ""
        elif column_type == "str":
            return ""
        elif column_type == "bool":
            return 0
        elif column_type == "int":
            return 0
        elif column_type == "float":
            return 0.0
        else:
            raise ValueError(f"Unhandled column type: {column_type}")

    def execute_query(self):
        cursor = self.get_db_connection().cursor()
        logger.info("Uploading codelists into temporary tables")
        for sql in self.codelist_tables:
            cursor.execute(sql)
        queries = list(self.queries)
        final_query = queries.pop()[1]
        for name, sql in queries:
            logger.info(f"Running query: {name}")
            cursor.execute(sql)
        output_table = self.get_output_table_name(os.environ.get("TEMP_DATABASE_NAME"))
        if output_table:
            logger.info(f"Running final query and writing output to '{output_table}'")
            sql = f"CREATE TABLE IF NOT EXISTS {output_table} AS {final_query}"
            cursor.execute(sql)
            logger.info(f"Downloading data from '{output_table}'")
            cursor.execute(f"SELECT * FROM {output_table}")
        else:
            logger.info(
                "No TEMP_DATABASE_NAME defined in environment, downloading results "
                "directly without writing to output table"
            )
            cursor.execute(final_query)
        return cursor

    def get_output_table_name(self, temporary_database):
        if not temporary_database:
            return
        timestamp = datetime.datetime.now(datetime.timezone.utc).strftime(
            "%Y%m%d_%H%M%S"
        )
        return f"{temporary_database}..Output_{timestamp}"

    def get_temp_table_prefix(self):
        if "TEMP_TABLE_PREFIX" in os.environ:
            return os.environ["TEMP_TABLE_PREFIX"]
        timestamp = datetime.datetime.now(datetime.timezone.utc).strftime(
            "%Y%m%d_%H%M%S"
        )
        return f"_{timestamp}_{uuid.uuid4().hex[:4]}"

    def make_temp_table_name(self, name):
        return f"{self.temp_table_prefix}_{name}"

    def get_query(self, column_name, query_type, query_args):
        method_name = f"patients_{query_type}"
        method = getattr(self, method_name)
        # Keep track of the current column name for debugging purposes
        self._current_column_name = column_name
        cols, sql = method(**query_args)
        assert (
            "hashed_organisation" in sql
        ), f"SQL for `{column_name}` must contain 'hashed_organisation'"
        self._current_column_name = None
        return cols, sql

    def create_codelist_table(self, codelist):
        table_number = len(self.codelist_tables) + 1
        # We include the current column name for ease of debugging
        column_name = self._current_column_name or "unknown"
        # The underscore prefix is our convention to indicate a temporary table
        # but has no significance for the database
        table_name = self.make_temp_table_name(f"{table_number}_{column_name}")
        cast = int if codelist.system in ("snomed", "snomedct", "dmd") else str
        organisation_hash = quote(get_organisation_hash())
        if codelist.has_categories:
            values = ", ".join(
                f"({quote(cast(code))}, {quote(category)})"
                for code, category in codelist
            )
            self.codelist_tables.append(
                f"""
                    CREATE TABLE IF NOT EXISTS {table_name} AS
                    SELECT code, category, {organisation_hash} AS hashed_organisation FROM (
                      VALUES {values}
                    ) AS t (code, category)
                    """
            )
        else:
            values = ", ".join(f"({quote(cast(code))})" for code in codelist)
            self.codelist_tables.append(
                f"""
                    CREATE TABLE IF NOT EXISTS {table_name} AS
                    SELECT code, {organisation_hash} AS hashed_organisation FROM (
                      VALUES {values}
                    ) AS t (code)
                    """
            )
        return table_name

    def patients_age_as_of(self, reference_date):
        quoted_date = quote(reference_date)
        return (
            ["patient_id", "age"],
            f"""
            SELECT
              registration_id AS patient_id,
              hashed_organisation,
              CASE WHEN
                 date_add('year', date_diff('year', date_of_birth, {quoted_date}), date_of_birth) > {quoted_date}
              THEN
                 date_diff('year', date_of_birth, {quoted_date}) - 1
              ELSE
                 date_diff('year', date_of_birth, {quoted_date})
              END AS age
            FROM {PATIENT_TABLE}
            """,
        )

    def patients_sex(self):
        return (
            ["patient_id", "sex"],
            f"""
          SELECT
            registration_id AS patient_id,
            hashed_organisation,
            CASE gender
              -- See https://www.datadictionary.nhs.uk/data_dictionary/attributes/p/person/person_gender_code_de.asp?shownav=1
              WHEN 1 THEN 'M'
              WHEN 2 THEN 'F'
              ELSE ''
            END AS sex
          FROM {PATIENT_TABLE}""",
        )

    def patients_all(self):
        """
        All patients
        """
        return (
            ["patient_id", "is_included"],
            f"""
            SELECT registration_id AS patient_id, hashed_organisation, 1 AS is_included
            FROM {PATIENT_TABLE}
            """,
        )

    def patients_most_recent_bmi(
        self,
        # Set date limits
        between=None,
        minimum_age_at_measurement=16,
        # Add an additional column indicating when measurement was taken
        include_date_of_match=False,
    ):
        """
        Return patients' most recent BMI (in the defined period) either
        computed from weight and height measurements or, where they are not
        availble, from recorded BMI values. Measurements taken when a patient
        was below the minimum age are ignored. The height measurement can be
        taken before (but not after) the defined period as long as the patient
        was over the minimum age at the time.

        Optionally returns an additional column with the date of the
        measurement. If the BMI is computed from weight and height then we use
        the date of the weight measurement for this.
        """
        # From https://github.com/ebmdatalab/tpp-sql-notebook/issues/10:
        #
        # 1) BMI calculated from last recorded height and weight
        #
        # 2) If height and weight is not available, then take latest
        # recorded BMI. Both values must be recorded when the patient
        # is >=16, weight must be within the last 10 years
        date_condition = make_date_filter("effective_date", between)

        # TODO these codes need validating
        bmi_code = 301331008  # Finding of body mass index (finding)
        weight_codes = codelist(
            [
                "27113001",  # Body weight (observable entity)
                "162763007",  # On examination - weight(finding)
            ],
            system="snomedct",
        )
        height_codes = codelist(
            [
                "271603002",  # Height / growth measure (observable entity)
                "162755006",  # On examination - height (finding)
            ],
            system="snomedct",
        )

        bmi_cte = f"""
        SELECT t.registration_id, t.BMI, t.effective_date
        FROM (
          SELECT registration_id, "value_pq_1" AS BMI, effective_date,
          ROW_NUMBER() OVER (PARTITION BY registration_id ORDER BY effective_date DESC) AS rownum
          FROM {OBSERVATION_TABLE}
          WHERE snomed_concept_id = {quote(bmi_code)} AND {date_condition}
        ) t
        WHERE t.rownum = 1
        """

        patients_cte = f"""
           SELECT registration_id, hashed_organisation, date_of_birth
           FROM {PATIENT_TABLE}
        """
        weight_codes_sql = codelist_to_sql(weight_codes)
        weights_cte = f"""
          SELECT t.registration_id, t.weight, t.effective_date
          FROM (
            SELECT registration_id, "value_pq_1" AS weight, effective_date,
            ROW_NUMBER() OVER (PARTITION BY registration_id ORDER BY effective_date DESC) AS rownum
            FROM {OBSERVATION_TABLE}
            WHERE snomed_concept_id IN ({weight_codes_sql}) AND {date_condition}
          ) t
          WHERE t.rownum = 1
        """

        height_codes_sql = codelist_to_sql(height_codes)
        # The height date restriction is different from the others. We don't
        # mind using old values as long as the patient was old enough when they
        # were taken.
        height_date_condition = make_date_filter(
            "effective_date",
            between,
            upper_bound_only=True,
        )
        heights_cte = f"""
          SELECT t.registration_id, t.height, t.effective_date
          FROM (
            SELECT registration_id, "value_pq_1" AS height, effective_date,
            ROW_NUMBER() OVER (PARTITION BY registration_id ORDER BY effective_date DESC) AS rownum
            FROM {OBSERVATION_TABLE}
            WHERE snomed_concept_id IN ({height_codes_sql}) AND {height_date_condition}
          ) t
          WHERE t.rownum = 1
        """

        min_age = int(minimum_age_at_measurement)

        sql = f"""
        SELECT
          patients.registration_id AS patient_id,
          hashed_organisation,
          CASE
            WHEN height = 0 THEN NULL
            ELSE ROUND(COALESCE(weight/(height*height), bmis.BMI), 1)
          END AS BMI,
          CASE
            WHEN weight IS NULL OR height IS NULL THEN DATE(bmis.effective_date)
            ELSE DATE(weights.effective_date)
          END AS date
        FROM ({patients_cte}) AS patients
        LEFT JOIN ({weights_cte}) AS weights
        ON weights.registration_id = patients.registration_id AND date_diff('year', patients.date_of_birth, weights.effective_date) >= {min_age}
        LEFT JOIN ({heights_cte}) AS heights
        ON heights.registration_id = patients.registration_id AND date_diff('year', patients.date_of_birth, heights.effective_date) >= {min_age}
        LEFT JOIN ({bmi_cte}) AS bmis
        ON bmis.registration_id = patients.registration_id AND date_diff('year', patients.date_of_birth, bmis.effective_date) >= {min_age}
        -- XXX maybe add a "WHERE NULL..." here
        """
        columns = ["patient_id", "BMI"]
        if include_date_of_match:
            columns.append("date")
        return columns, sql

    def patients_mean_recorded_value(
        self,
        codelist,
        # What period is the mean over? (Only one supported option for now)
        on_most_recent_day_of_measurement=None,
        # Set date limits
        between=None,
        # Add additional columns indicating when measurement was taken
        include_date_of_match=False,
    ):
        # We only support this option for now
        assert on_most_recent_day_of_measurement
        date_condition = make_date_filter("effective_date", between)
        codelist_sql = codelist_to_sql(codelist)
        # The subquery finds, for each patient, the most recent day on which
        # they've had a measurement. The outer query selects, for each patient,
        # the mean value on that day.
        # Note, there's a CAST in the JOIN condition but apparently SQL Server can still
        # use an index for this. See: https://stackoverflow.com/a/25564539
        sql = f"""
        SELECT
          days.registration_id AS patient_id,
          days.hashed_organisation,
          AVG({OBSERVATION_TABLE}."value_pq_1") AS mean_value,
          days.date_measured AS date
        FROM (
            SELECT
                registration_id,
                hashed_organisation,
                CAST(MAX(effective_date) AS date) AS date_measured
            FROM {OBSERVATION_TABLE}
            WHERE snomed_concept_id IN ({codelist_sql}) AND {date_condition}
            GROUP BY registration_id, hashed_organisation
        ) AS days
        LEFT JOIN {OBSERVATION_TABLE}
        ON (
          {OBSERVATION_TABLE}.registration_id = days.registration_id
          AND {OBSERVATION_TABLE}.snomed_concept_id IN ({codelist_sql})
          AND CAST({OBSERVATION_TABLE}.effective_date AS date) = days.date_measured
        )
        GROUP BY days.registration_id, days.hashed_organisation, days.date_measured
        """
        columns = ["patient_id", "mean_value"]
        if include_date_of_match:
            columns.append("date")
        return columns, sql

    def patients_registered_as_of(self, reference_date):
        """
        All patients registed on the given date
        """
        return self.patients_registered_with_one_practice_between(
            reference_date, reference_date
        )

    def patients_registered_with_one_practice_between(self, start_date, end_date):
        """
        All patients registered with the same practice through the given period
        """
        return (
            ["patient_id", "is_registered"],
            f"""
            SELECT
                {PATIENT_TABLE}.registration_id AS patient_id,
                hashed_organisation,
                1 AS is_registered
            FROM {PATIENT_TABLE}
            WHERE registered_date <= {quote(start_date)}
              AND (registration_end_date > {quote(end_date)} OR registration_end_date IS NULL)
            """,
        )

    def patients_with_these_medications(self, **kwargs):
        """
        Patients who have been prescribed at least one of this list of
        medications in the defined period
        """
        assert kwargs["codelist"].system in ("snomed", "snomedct")
        if kwargs["returning"] == "numeric_value":
            raise ValueError("Unsupported `returning` value: numeric_value")
        # This uses a special case function with a "fake it til you make it" API
        if kwargs["returning"] == "number_of_episodes":
            kwargs.pop("returning")
            # Remove unhandled arguments and check they are unused
            assert not kwargs.pop("find_first_match_in_period", None)
            assert not kwargs.pop("find_last_match_in_period", None)
            assert not kwargs.pop("include_date_of_match", None)
            return self._number_of_episodes_by_medication(**kwargs)
        # This is the default code path for most queries
        else:
            # Remove unhandled arguments and check they are unused
            assert not kwargs.pop("episode_defined_as", None)
            return self._patients_with_events(
                MEDICATION_TABLE,
                "",
                "snomed_concept_id",
                **kwargs,
            )

    def patients_with_these_clinical_events(self, **kwargs):
        """
        Patients who have had at least one of these clinical events in the
        defined period
        """
        assert kwargs["codelist"].system in ("snomed", "snomedct")
        # This uses a special case function with a "fake it til you make it" API
        if kwargs["returning"] == "number_of_episodes":
            kwargs.pop("returning")
            # Remove unhandled arguments and check they are unused
            assert not kwargs.pop("find_first_match_in_period", None)
            assert not kwargs.pop("find_last_match_in_period", None)
            assert not kwargs.pop("include_date_of_match", None)
            return self._number_of_episodes_by_clinical_event(**kwargs)
        # This is the default code path for most queries
        else:
            assert not kwargs.pop("episode_defined_as", None)
            return self._patients_with_events(
                OBSERVATION_TABLE,
                "",
                "snomed_concept_id",
                **kwargs,
            )

    def _patients_with_events(
        self,
        from_table,
        additional_join,
        code_column,
        codelist,
        # Allows us to say: find codes A and B, but only on days where X and Y
        # didn't happen
        ignore_days_where_these_codes_occur=None,
        # Set date limits
        between=None,
        # Matching rule
        find_first_match_in_period=None,
        find_last_match_in_period=None,
        # Set return type
        returning="binary_flag",
        include_date_of_match=False,
        ignore_missing_values=False,
    ):
        codelist_table = self.create_codelist_table(codelist)
        date_condition = make_date_filter("effective_date", between)
        not_an_ignored_day_condition = self._none_of_these_codes_occur_on_same_day(
            from_table, ignore_days_where_these_codes_occur
        )
        missing_value_condition = (
            "(value_pq_1 IS NOT NULL AND value_pq_1 != 0)"
            if ignore_missing_values
            else "1 = 1"
        )

        # Result ordering
        if find_first_match_in_period:
            ordering = "ASC"
            date_aggregate = "MIN"
        else:
            ordering = "DESC"
            date_aggregate = "MAX"

        query_column = None
        if returning == "binary_flag" or returning == "date":
            column_name = "has_event"
            column_definition = "1"
            use_partition_query = False
        elif returning == "number_of_matches_in_period":
            column_name = "count"
            column_definition = "COUNT(*)"
            use_partition_query = False
        elif returning == "numeric_value":
            column_name = "value"
            column_definition = '"value_pq_1"'
            use_partition_query = True
        elif returning == "code":
            column_name = "code"
            column_definition = f"CAST({code_column} AS VARCHAR(18))"
            query_column = code_column
            use_partition_query = True
        elif returning == "category":
            if not codelist.has_categories:
                raise ValueError(
                    "Cannot return categories because the supplied codelist does "
                    "not have any categories defined"
                )
            column_name = "category"
            column_definition = "category"
            use_partition_query = True
        else:
            raise ValueError(f"Unsupported `returning` value: {returning}")

        if query_column is None:
            query_column = column_definition

        if use_partition_query:
            sql = f"""
            SELECT
              registration_id AS patient_id,
              hashed_organisation,
              {column_definition} AS {column_name},
              DATE(effective_date) AS date
            FROM (
              SELECT
                registration_id,
                {from_table}.hashed_organisation,
                {query_column},
                effective_date,
                ROW_NUMBER() OVER (
                  PARTITION BY registration_id ORDER BY effective_date {ordering}
                ) AS rownum
              FROM {from_table}{additional_join}
              INNER JOIN {codelist_table}
              ON {code_column} = {codelist_table}.code
              WHERE {date_condition}
                AND {not_an_ignored_day_condition}
                AND {missing_value_condition}
            ) t
            WHERE rownum = 1
            """
        else:
            sql = f"""
            SELECT
              registration_id AS patient_id,
              {from_table}.hashed_organisation,
              {column_definition} AS {column_name},
              {date_aggregate}(DATE(effective_date)) AS date
            FROM {from_table}{additional_join}
            INNER JOIN {codelist_table}
            ON {code_column} = {codelist_table}.code
            WHERE {date_condition}
              AND {not_an_ignored_day_condition}
              AND {missing_value_condition}
            GROUP BY registration_id, {from_table}.hashed_organisation
            """

        if returning == "date":
            columns = ["patient_id", "date"]
        else:
            columns = ["patient_id", column_name]
            if include_date_of_match:
                columns.append("date")
        return columns, sql

    def _number_of_episodes_by_medication(
        self,
        codelist,
        # Set date limits
        between=None,
        ignore_days_where_these_codes_occur=None,
        episode_defined_as=None,
    ):
        codelist_table = self.create_codelist_table(codelist)
        date_condition = make_date_filter("effective_date", between)
        not_an_ignored_day_condition = self._none_of_these_codes_occur_on_same_day(
            MEDICATION_TABLE, ignore_days_where_these_codes_occur
        )
        if episode_defined_as is not None:
            pattern = r"^series of events each <= (\d+) days apart$"
            match = re.match(pattern, episode_defined_as)
            if not match:
                raise ValueError(
                    f"Argument `episode_defined_as` must match " f"pattern: {pattern}"
                )
            washout_period = int(match.group(1))
        else:
            washout_period = 0

        sql = f"""
        SELECT
          registration_id AS patient_id,
          hashed_organisation,
          SUM(is_new_episode) AS episode_count
        FROM (
            SELECT
              registration_id,
              {MEDICATION_TABLE}.hashed_organisation,
              CASE
                WHEN
                  date_diff(
                    'day',
                    LAG(effective_date) OVER (PARTITION BY registration_id ORDER BY effective_date),
                    effective_date
                  ) <= {washout_period}
                THEN 0
                ELSE 1
              END AS is_new_episode
            FROM {MEDICATION_TABLE}
            INNER JOIN {codelist_table}
            ON snomed_concept_id = {codelist_table}.code
            WHERE {date_condition} AND {not_an_ignored_day_condition}
        ) t
        GROUP BY registration_id, hashed_organisation
        """
        return ["patient_id", "episode_count"], sql

    def _number_of_episodes_by_clinical_event(
        self,
        codelist,
        # Set date limits
        between=None,
        ignore_days_where_these_codes_occur=None,
        episode_defined_as=None,
        ignore_missing_values=False,
    ):
        codelist_table = self.create_codelist_table(codelist)
        date_condition = make_date_filter("effective_date", between)
        not_an_ignored_day_condition = self._none_of_these_codes_occur_on_same_day(
            OBSERVATION_TABLE, ignore_days_where_these_codes_occur
        )
        missing_value_condition = (
            "(value_pq_1 IS NOT NULL AND value_pq_1 != 0)"
            if ignore_missing_values
            else "1 = 1"
        )

        if episode_defined_as is not None:
            pattern = r"^series of events each <= (\d+) days apart$"
            match = re.match(pattern, episode_defined_as)
            if not match:
                raise ValueError(
                    f"Argument `episode_defined_as` must match " f"pattern: {pattern}"
                )
            washout_period = int(match.group(1))
        else:
            washout_period = 0

        sql = f"""
        SELECT
          registration_id AS patient_id,
          hashed_organisation,
          SUM(is_new_episode) AS episode_count
        FROM (
            SELECT
              registration_id,
              {OBSERVATION_TABLE}.hashed_organisation,
              CASE
                WHEN
                  date_diff(
                    'day',
                    LAG(effective_date) OVER (PARTITION BY registration_id ORDER BY effective_date),
                    effective_date
                  ) <= {washout_period}
                THEN 0
                ELSE 1
              END AS is_new_episode
            FROM {OBSERVATION_TABLE}
            INNER JOIN {codelist_table}
            ON snomed_concept_id = {codelist_table}.code
            WHERE {date_condition}
              AND {not_an_ignored_day_condition}
              AND {missing_value_condition}
        ) t
        GROUP BY registration_id, hashed_organisation
        """
        return ["patient_id", "episode_count"], sql

    def _none_of_these_codes_occur_on_same_day(self, joined_table, codelist):
        """
        Generates a SQL condition that filters rows in `joined_table` so that
        they only include events which happened on days where none of the codes
        in `codelist` occur in the CodedEvents table.

        We use this to support queries like "give me all the times a patient
        was prescribed this drug, but ignore any days on which they were having
        their annual COPD review".
        """
        if codelist is None:
            return "1 = 1"
        codelist_table = self.create_codelist_table(codelist)
        return f"""
        NOT EXISTS (
          SELECT * FROM {OBSERVATION_TABLE} AS sameday
          INNER JOIN {codelist_table}
          ON sameday.snomed_concept_id = {codelist_table}.code
          WHERE
            sameday.registration_id = {joined_table}.registration_id
            AND CAST(sameday.effective_date AS date) = CAST({joined_table}.effective_date AS date)
        )
        """

    def patients_registered_practice_as_of(self, date, returning=None):
        # At the moment we can only return current values for the fields in question.
        self.validate_recent_date(date)

        if returning == "stp_code":
            column = "stp_code"
        elif returning == "msoa_code":
            column = "msoa"
        elif returning == "nuts1_region_name":
            column = "english_region_name"
        elif returning == "pseudo_id":
            column = "hashed_organisation"
        else:
            raise ValueError(f"Unsupported `returning` value: {returning}")

        return (
            ["patient_id", returning],
            f"""
            SELECT
              registration_id AS patient_id,
              hashed_organisation,
              {column} AS {returning}
            FROM
              {PATIENT_TABLE}
            """,
        )

    def patients_with_death_recorded_in_primary_care(
        self,
        # Set date limits
        between=None,
        # Set return type
        returning="binary_flag",
    ):
        if returning == "binary_flag":
            column = "1"
        elif returning == "date_of_death":
            column = "date_of_death"
        else:
            raise ValueError(f"Unsupported `returning` value: {returning}")
        if between is None:
            between = (None, None)
        min_date, max_date = between
        if max_date is None:
            max_date = "9999-12-31"  # Far enough in the future to catch everyone
        if min_date is None:
            min_date = "1900-01-01"  # Far enough in the path to catch everyone
        return (
            ["patient_id", returning],
            f"""
        SELECT
          registration_id AS patient_id,
          hashed_organisation,
          {column} AS {returning}
        FROM
          {PATIENT_TABLE}
        WHERE
          date_of_death BETWEEN {quote(min_date)} AND {quote(max_date)}
        """,
        )

    def patients_with_vaccination_record(
        self,
        tpp,
        emis,
        # Set date limits
        between=None,
        # Set return type
        returning="binary_flag",
        # Matching rule
        find_first_match_in_period=None,
        find_last_match_in_period=None,
    ):
        product_codes = emis.get("product_codes")
        procedure_codes = emis.get("procedure_codes")

        if returning not in ("binary_flag", "date"):
            raise ValueError(f"Unsupported `returning` value: {returning}")

        date_condition = make_date_filter("effective_date", between)
        if find_first_match_in_period:
            date_aggregate = "MIN"
            date_comparator = "<"
        else:
            date_aggregate = "MAX"
            date_comparator = ">"

        if product_codes:
            product_codes_table = self.create_codelist_table(product_codes)
        if procedure_codes:
            procedure_codes_table = self.create_codelist_table(procedure_codes)

        if procedure_codes and product_codes:
            sql = f"""
            SELECT
                patient_id,
                hashed_organisation,
                1 AS has_event,
                {date_aggregate}(DATE(date)) AS date
            FROM (
                SELECT
                    m.registration_id AS patient_id,
                    m.hashed_organisation AS hashed_organisation,
                    1 AS has_event,
                    CASE
                        WHEN m.effective_date {date_comparator} i.effective_date THEN m.effective_date
                        ELSE i.effective_date
                    END AS date
                FROM {MEDICATION_TABLE} AS m
                INNER JOIN {IMMUNISATIONS_TABLE} AS i
                    ON m.registration_id = i.registration_id
                INNER JOIN {product_codes_table}
                    ON m.snomed_concept_id = {product_codes_table}.code
                INNER JOIN {procedure_codes_table}
                    ON i.snomed_concept_id = {procedure_codes_table}.code
                WHERE {date_condition}
            )
            GROUP BY patient_id, hashed_organisation
            """

        elif procedure_codes:
            assert not product_codes
            sql = f"""
            SELECT
                registration_id AS patient_id,
                i.hashed_organisation AS hashed_organisation,
                1 AS has_event,
                {date_aggregate}(DATE(effective_date)) AS date
            FROM {IMMUNISATIONS_TABLE} AS i
            INNER JOIN {procedure_codes_table}
                ON i.snomed_concept_id = {procedure_codes_table}.code
            WHERE {date_condition}
            GROUP BY registration_id, i.hashed_organisation
            """

        elif product_codes:
            assert not procedure_codes
            sql = f"""
            SELECT
                registration_id AS patient_id,
                m.hashed_organisation AS hashed_organisation,
                1 AS has_event,
                {date_aggregate}(DATE(effective_date)) AS date
            FROM {MEDICATION_TABLE} AS m
            INNER JOIN {product_codes_table}
                ON m.snomed_concept_id = {product_codes_table}.code
            WHERE {date_condition}
            GROUP BY registration_id, m.hashed_organisation
            """

        else:
            raise ValueError(
                "Provide at least one of `product_codes` or `procedure_codes`"
            )

        if returning == "date":
            columns = ["patient_id", "date"]
        else:
            columns = ["patient_id", "has_event"]
        return columns, sql

    def patients_address_as_of(self, date, returning=None, round_to_nearest=None):
        # At the moment we can only return current values for the fields in question.
        self.validate_recent_date(date)

        if returning == "index_of_multiple_deprivation":
            assert round_to_nearest == 100
            column = "imd_rank"
        elif returning == "rural_urban_classification":
            assert round_to_nearest is None
            column = "rural_urban"
        else:
            raise ValueError(f"Unsupported `returning` value: {returning}")

        return (
            ["patient_id", returning],
            f"""
            SELECT
              registration_id AS patient_id,
              hashed_organisation,
              {column} AS {returning}
            FROM
              {PATIENT_TABLE}
            """,
        )

    # https://github.com/ebmdatalab/tpp-sql-notebook/issues/72
    def patients_admitted_to_icu(
        self,
        between=None,
        find_first_match_in_period=None,
        find_last_match_in_period=None,
        returning="binary_flag",
    ):
        if find_first_match_in_period:
            date_aggregate = "MIN"
            date_column_name = "first_admitted_date"
        else:
            date_aggregate = "MAX"
            date_column_name = "last_admitted_date"
        date_expression = f"""
        {date_aggregate}(
        CASE
        WHEN
          COALESCE(date_format(icuadmissiondatetime, '%Y-%m-%d'), '9999-01-01') < COALESCE(date_format(originalicuadmissiondate, '%Y-%m-%d'), '9999-01-01')
        THEN
          DATE(icuadmissiondatetime)
        ELSE
          DATE(originalicuadmissiondate)
        END)"""
        date_condition = make_date_filter(date_expression, between)

        if returning == "date_admitted":
            column_name = date_column_name
            column_definition = date_expression
        elif returning == "binary_flag":
            column_name = "was_admitted"
            column_definition = 1
        else:
            assert False, "`returning` must be one of `binary_flag` or `date_admitted`"
        return (
            ["patient_id", column_name],
            f"""
            SELECT
              registration_id AS patient_id,
              hashed_organisation,
              {column_definition} AS {column_name},
              MAX(Ventilator) AS ventilated -- apparently can be 0, 1 or NULL
            FROM
              {ICNARC_TABLE}
            GROUP BY registration_id, hashed_organisation
            HAVING
              {date_condition} AND SUM(basicdays_respiratorysupport) + SUM(advanceddays_respiratorysupport) >= 1
            """,
        )

    def patients_with_these_codes_on_death_certificate(
        self,
        codelist=None,
        # Set date limits
        between=None,
        # Matching rules
        match_only_underlying_cause=False,
        # Set return type
        returning="binary_flag",
    ):
        date_condition = make_date_filter(
            "date_parse(CAST(o.reg_stat_dod AS VARCHAR), '%Y%m%d')", between
        )
        if codelist is not None:
            assert codelist.system == "icd10"
            codelist_sql = codelist_to_sql(codelist)
            code_columns = ["icd10u"]
            if not match_only_underlying_cause:
                code_columns.extend([f"icd10{i:03d}" for i in range(1, 16)])
            code_conditions = " OR ".join(
                f"{column} IN ({codelist_sql})" for column in code_columns
            )
        else:
            code_conditions = "1 = 1"
        if returning == "binary_flag":
            column_definition = "1"
            column_name = "died"
        elif returning == "date_of_death":
            # Yes, we're converting an integer to a string to a timestamp to a date.
            column_definition = (
                "CAST(date_parse(CAST(o.reg_stat_dod AS VARCHAR), '%Y%m%d') AS date)"
            )
            column_name = "date_of_death"
        elif returning == "underlying_cause_of_death":
            column_definition = "o.icd10u"
            column_name = "underlying_cause_of_death"
        else:
            raise ValueError(f"Unsupported `returning` value: {returning}")
        return (
            ["patient_id", column_name],
            # ONS_TABLE is updated with each release of data from ONS, so we need to
            # filter for just the records which match the most recent upload_date
            f"""
            SELECT
                p.registration_id as patient_id,
                p.hashed_organisation as hashed_organisation,
                {column_definition} AS {column_name}
            FROM {ONS_TABLE} o
            JOIN {PATIENT_TABLE} p ON o.pseudonhsnumber = p.nhs_no
            WHERE ({code_conditions})
                AND {date_condition}
                AND date_parse(o.upload_date, '%d/%m/%Y') = (
                    SELECT MAX(date_parse(upload_date, '%d/%m/%Y')) FROM {ONS_TABLE}
                )
            """,
        )

    def patients_died_from_any_cause(
        self,
        # Set date limits
        between=None,
        # Set return type
        returning="binary_flag",
    ):
        return self.patients_with_these_codes_on_death_certificate(
            codelist=None,
            between=between,
            returning=returning,
        )

    def patients_with_death_recorded_in_cpns(
        self,
        # Set date limits
        between=None,
        # Set return type
        returning="binary_flag",
    ):
        date_condition = make_date_filter("dateofdeath", between)
        if returning == "binary_flag":
            column_definition = "1"
            column_name = "died"
        elif returning == "date_of_death":
            column_definition = "MAX(dateofdeath)"
            column_name = "date_of_death"
        else:
            raise ValueError(f"Unsupported `returning` value: {returning}")
        return (
            ["patient_id", column_name],
            f"""
            SELECT
              registration_id as patient_id,
              hashed_organisation,
              {column_definition} AS {column_name},
              -- Crude error check so we blow up in the case of inconsistent dates
              1 / CASE WHEN MAX(dateofdeath) = MIN(dateofdeath) THEN 1 ELSE 0 END AS _e
            FROM {CPNS_TABLE}
            WHERE {date_condition}
            GROUP BY registration_id, hashed_organisation
            """,
        )

    def get_case_expression(
        self, column_types, column_definitions, category_definitions
    ):
        category_definitions = category_definitions.copy()
        defaults = [k for (k, v) in category_definitions.items() if v == "DEFAULT"]
        if len(defaults) > 1:
            raise ValueError("At most one default category can be defined")
        if len(defaults) == 1:
            default_value = defaults[0]
            category_definitions.pop(default_value)
        else:
            raise ValueError(
                "At least one category must be given the definition 'DEFAULT'"
            )
        # For each column already defined, determine its corresponding "empty"
        # value (i.e. the default value for that column's type). This allows us
        # to support implicit boolean conversion because we know what the
        # "falsey" value for each column should be.
        empty_value_map = {
            name: self.get_default_value_for_type(column_type)
            for name, column_type in column_types.items()
        }
        clauses = []
        for category, expression in category_definitions.items():
            # The column references in the supplied expression need to be
            # rewritten to ensure they refer to the correct CTE. The formatting
            # function also ensures that the expression matches the very
            # limited subset of SQL we support here.
            formatted_expression, _ = format_expression(
                expression, column_definitions, empty_value_map=empty_value_map
            )
            clauses.append(f"WHEN ({formatted_expression}) THEN {quote(category)}")
        return f"CASE {' '.join(clauses)} ELSE {quote(default_value)} END"

    def get_db_connection(self):
        if self._db_connection:
            return self._db_connection
        self._db_connection = presto_connection_from_url(self.database_url)
        return self._db_connection

    def close(self):
        if self._db_connection:
            self._db_connection.close()
        self._db_connection = None

    def validate_recent_date(self, date, max_delta_days=30):
        pass
        date = datetime.datetime.strptime(date, "%Y-%m-%d").date()
        delta = datetime.date.today() - date
        if delta.days > max_delta_days:
            msg = f"{self._current_column_name} should be passed a date more recent than {max_delta_days} days in the past"
            warnings.warn(msg)

    def get_aggregate_expression(
        self, column_type, column_definitions, column_names, aggregate_function
    ):
        """Return an expression that is used to find the maximum or minimum value across
        a number of other given columns.

        We cannot use Table Value Constructors as in the TPP backend (this gives a
        cryptic error message: "Given correlated subquery is not supported").

        Instead, we use GREATEST() or LEAST(), but we have to be careful to handle
        correctly any arguments to GREATEST/LEAST that have replaced NULLs.  To do this,
        we replace any occurences of the default value for the given column_type with
        the most extreme value possible for the column_type.  (So when finding the
        maximum, we replace the default value with a small value, and when finding the
        minimum, with a large value.)

        If all the arguments to GREATEST/LEAST have replaced NULLs, GREATEST/LEAST will
        return the extreme value, so when that happens, we have to replace this with the
        default value for the column type.

        This gives us the result we want but it does mean we can't distinguish e.g. a
        recorded value of 0.0 from a missing value.  This, however, is a general problem
        with the way we handle NULLs in our system, and so we're not introducing any new
        difficulty here.  (It's also unlikely to be a problem in practice.)
        """

        default_value = quote(self.get_default_value_for_type(column_type))
        function = {"MAX": "GREATEST", "MIN": "LEAST"}[aggregate_function]

        if column_type in ["int", "float"]:
            extreme_value_lookup = {"MAX": -(2 ** 63), "MIN": 2 ** (63 - 1)}
            extreme_value = [aggregate_function]
        elif column_type == "date":
            extreme_value_lookup = {"MAX": "'0001-01-01'", "MIN": "'9999-12-31'"}
        else:
            assert False, column_type
        extreme_value = extreme_value_lookup[aggregate_function]

        components = ", ".join(
            f"""
            CASE WHEN {column_definitions[name]} = {default_value}
                THEN {extreme_value}
            ELSE {column_definitions[name]} END"""
            for name in column_names
        )

        return f"""
        CASE WHEN {function}({components}) = {extreme_value}
            THEN {default_value}
        ELSE {function}({components}) END"""


def codelist_to_sql(codelist):
    cast = int if codelist.system in ("snomed", "snomedct") else str
    if getattr(codelist, "has_categories", False):
        values = [quote(cast(code)) for (code, category) in codelist]
    else:
        values = [quote(cast(code)) for code in codelist]
    return ",".join(values)


def quote(value):
    if isinstance(value, (int, float)):
        return str(value)

    value = str(value)

    if re.match(r"^\w+ \+ interval '\d+' (day|month|year)$", value):
        return value

    try:
        datetime.datetime.strptime(value, "%Y-%m-%d")
        return f"DATE('{value}')"
    except ValueError:
        pass

    if not SAFE_CHARS_RE.match(value) and value != "":
        raise ValueError(f"Value contains disallowed characters: {value}")
    return f"'{value}'"


def make_date_filter(column, between, upper_bound_only=False):
    if between is None:
        between = (None, None)
    min_date, max_date = between
    if upper_bound_only:
        min_date = None
    if min_date is not None and max_date is not None:
        return f"{column} BETWEEN {quote(min_date)} AND {quote(max_date)}"
    elif min_date is not None:
        return f"{column} >= {quote(min_date)}"
    elif max_date is not None:
        return f"{column} <= {quote(max_date)}"
    else:
        return "1=1"


def truncate_date(column, date_format):
    if date_format == "YYYY" or date_format is None:
        date_format = "%Y"
    elif date_format == "YYYY-MM":
        date_format = "%Y-%m"
    elif date_format == "YYYY-MM-DD":
        date_format = "%Y-%m-%d"
    else:
        raise ValueError(f"Unhandled date format: {date_format}")
    return f"date_format({column}, '{date_format}')"


class UniqueCheck:
    def __init__(self):
        self.count = 0
        self.ids = set()

    def add(self, item):
        self.count += 1
        self.ids.add(item)

    def assert_unique_ids(self):
        duplicates = self.count - len(self.ids)
        if duplicates != 0:
            print("-" * 80)
            print(f"Duplicate IDs found ({duplicates} rows)")
            print("-" * 80)


def pop_keys_from_dict(dictionary, keys):
    new_dict = {}
    for key in keys:
        if key in dictionary:
            new_dict[key] = dictionary.pop(key)
    return new_dict


def get_organisation_hash():
    return os.environ["EMIS_ORGANISATION_HASH"]
