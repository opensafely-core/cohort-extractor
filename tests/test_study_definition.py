import csv
import subprocess
import sys
import textwrap

import pandas
import pytest

from cohortextractor import StudyDefinition, codelist, patients
from cohortextractor.cohortextractor import SUPPORTED_FILE_FORMATS
from cohortextractor.exceptions import DummyDataValidationError
from cohortextractor.validate_dummy_data import validate_dummy_data


def test_create_dummy_data_works_without_database_url(tmp_path, monkeypatch):
    monkeypatch.delenv("DATABASE_URL", raising=False)
    study = StudyDefinition(
        population=patients.all(),
        sex=patients.sex(
            return_expectations={
                "rate": "universal",
                "date": {"earliest": "1900-01-01", "latest": "today"},
                "category": {"ratios": {"M": 0.49, "F": 0.51}},
            }
        ),
        age=patients.age_as_of(
            "2020-01-01",
            return_expectations={
                "rate": "universal",
                "date": {"earliest": "1900-01-01", "latest": "2020-01-01"},
                "int": {"distribution": "population_ages"},
            },
        ),
    )
    filename = tmp_path / "dummy_data.csv"
    study.to_file(filename, expectations_population=10)
    with open(filename) as f:
        results = list(csv.DictReader(f))
    assert len(results) == 10
    columns = results[0].keys()
    assert "sex" in columns
    assert "age" in columns


@pytest.mark.parametrize("file_format", SUPPORTED_FILE_FORMATS)
def test_to_file_with_expectations_population(tmp_path, file_format):
    cl = codelist([("12345", "foo"), ("67890", "bar")], system="snomed")
    study = StudyDefinition(
        default_expectations={"date": {"earliest": "2020-01-01", "latest": "today"}},
        population=patients.all(),
        sex=patients.sex(
            return_expectations={
                "category": {"ratios": {"F": 0.5, "M": 0.5}},
                "rate": "universal",
            },
        ),
        age=patients.age_as_of(
            "2020-01-01",
            return_expectations={
                "int": {"distribution": "population_ages"},
                "rate": "universal",
            },
        ),
        has_event=patients.with_these_clinical_events(
            cl,
            returning="binary_flag",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
        event_date_day=patients.with_these_clinical_events(
            cl,
            returning="date",
            date_format="YYYY-MM-DD",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
        event_date_month=patients.with_these_clinical_events(
            cl,
            returning="date",
            date_format="YYYY-MM",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
        event_date_year=patients.with_these_clinical_events(
            cl,
            returning="date",
            date_format="YYYY",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
        incomplete_categories=patients.with_these_clinical_events(
            cl,
            returning="category",
            return_expectations={
                "category": {"ratios": {"foo": 0.5, "bar": 0.5}},
                # Half the values here should be null
                "incidence": 0.5,
            },
        ),
    )

    dummy_data_file = tmp_path / f"dummy-data.{file_format}"
    study.to_file(dummy_data_file, expectations_population=100)
    # We reuse validate_dummy_data to check that the data generated by the expectations
    # framework is valid.
    validate_dummy_data(study.covariate_definitions, dummy_data_file)


@pytest.mark.parametrize("file_format", SUPPORTED_FILE_FORMATS)
def test_to_file_with_dummy_data_file(tmp_path, file_format):
    cl = codelist(["12345"], system="snomed")
    study = StudyDefinition(
        default_expectations={"date": {"earliest": "2020-01-01", "latest": "today"}},
        population=patients.all(),
        sex=patients.sex(
            return_expectations={
                "category": {"ratios": {"F": 0.5, "M": 0.5}},
                "rate": "universal",
            },
        ),
        age=patients.age_as_of(
            "2020-01-01",
            return_expectations={
                "int": {"distribution": "population_ages"},
                "rate": "universal",
            },
        ),
        has_event=patients.with_these_clinical_events(
            cl,
            returning="binary_flag",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
        event_date_day=patients.with_these_clinical_events(
            cl,
            returning="date",
            date_format="YYYY-MM-DD",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
        event_date_month=patients.with_these_clinical_events(
            cl,
            returning="date",
            date_format="YYYY-MM",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
        event_date_year=patients.with_these_clinical_events(
            cl,
            returning="date",
            date_format="YYYY",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
    )

    # Generate dummy data using the expectations framework
    dummy_data_file = tmp_path / f"dummy-data.{file_format}"
    study.to_file(dummy_data_file, expectations_population=10)

    # Use this dummy data
    output_file = tmp_path / f"output.{file_format}"
    study.to_file(output_file, dummy_data_file=dummy_data_file)

    # Check results
    with open(dummy_data_file, "rb") as f:
        dummy_data = f.read()

    with open(output_file, "rb") as f:
        expected_output = f.read()

    assert dummy_data == expected_output


def test_to_file_with_dummy_data_file_incorrect_extension(tmp_path):
    study = StudyDefinition(population=patients.all())
    with pytest.raises(DummyDataValidationError):
        study.to_file(
            tmp_path / "output.csv.gz", dummy_data_file=tmp_path / "dummy-data-csv"
        )


def test_export_data_without_database_url_raises_error(tmp_path, monkeypatch):
    monkeypatch.delenv("DATABASE_URL", raising=False)
    study = StudyDefinition(
        population=patients.all(),
        sex=patients.sex(),
        age=patients.age_as_of(
            "2020-01-01",
        ),
    )
    with pytest.raises(RuntimeError):
        study.to_file(tmp_path / "dummy_data.csv")


def test_unrecognised_database_url_raises_error(monkeypatch):
    monkeypatch.setenv("DATABASE_URL", "unknown-db://localhost")
    with pytest.raises(ValueError):
        StudyDefinition(
            population=patients.all(),
            sex=patients.sex(),
            age=patients.age_as_of(
                "2020-01-01",
            ),
        )


def test_errors_are_triggered_without_database_url(monkeypatch):
    monkeypatch.delenv("DATABASE_URL", raising=False)
    with pytest.raises(KeyError):
        StudyDefinition(
            population=patients.satisfying("no_such_column AND missing_column"),
            sex=patients.sex(),
            age=patients.age_as_of(
                "2020-01-01",
            ),
        )


def test_drivers_not_accidentally_imported(tmp_path):
    """
    For now, we still have to support researchers importing their study
    definitions in their analysis code to access details of their study
    configuration (and avoid having to repeat this in two places). To enable
    this we install a version of the cohortextractor inside the `python-docker`
    image but without any of the driver packages (which are large and unused
    and would bloat the image). But this means we need to make sure we don't
    accidentally create a dependency on one of the driver packages when loading
    a study definition. So this test ensures that we can import a basic study
    definition and generate some dummy data without ever importing a driver.
    """
    # To track imports we need to execute a test script in a separate process
    test_script = """
        import sys

        from cohortextractor import StudyDefinition, patients

        study = StudyDefinition(
            population=patients.all(),
            sex=patients.sex(
                return_expectations={
                    "rate": "universal",
                    "date": {"earliest": "1900-01-01", "latest": "today"},
                    "category": {"ratios": {"M": 0.49, "F": 0.51}},
                }
            ),
        )
        study.to_file("{tmp_path}/dummy.csv", expectations_population=10)
        drivers = ["pymssql", "pyodbc", "ctds", "trino"]
        imported_drivers = [i for i in drivers if i in sys.modules]
        print(f"imported_drivers={imported_drivers}")
    """

    source = textwrap.dedent(test_script)
    source = source.replace("{tmp_path}", str(tmp_path))
    result = subprocess.check_output([sys.executable, "-c", source]).strip()
    assert result == b"imported_drivers=[]"


def test_column_name_clashes_produce_errors():
    with pytest.raises(ValueError):
        StudyDefinition(
            population=patients.all(),
            age=patients.age_as_of("2020-01-01"),
            status=patients.satisfying(
                "age > 70 AND sex = 'M'",
                sex=patients.sex(),
                age=patients.age_as_of("2010-01-01"),
            ),
        )


def test_recursive_definitions_produce_errors():
    with pytest.raises(ValueError):
        StudyDefinition(
            population=patients.all(),
            this=patients.satisfying("that = 1"),
            that=patients.satisfying("this = 1"),
        )


def test_syntax_errors_in_expressions_are_raised():
    with pytest.raises(ValueError):
        StudyDefinition(
            population=patients.all(),
            status=patients.satisfying(
                "age > 70 AND AND sex = 'M'",
                sex=patients.sex(),
                age=patients.age_as_of("2010-01-01"),
            ),
        )


@pytest.mark.parametrize("file_format", SUPPORTED_FILE_FORMATS)
def test_booleans_correctly_handled_in_dummy_data(tmp_path, file_format):
    cl = codelist(["12345"], system="snomed")
    study = StudyDefinition(
        default_expectations={"date": {"earliest": "2020-01-01", "latest": "today"}},
        population=patients.all(),
        has_event=patients.with_these_clinical_events(
            cl,
            returning="binary_flag",
            return_expectations={"rate": "uniform", "incidence": 0.5},
        ),
    )

    filename = tmp_path / f"dummy-data.{file_format}"
    study.to_file(filename, expectations_population=100)

    if file_format in ("csv", "csv.gz"):
        df = pandas.read_csv(filename, dtype=str)
        bools = ("0", "1")
    elif file_format == "feather":
        df = pandas.read_feather(filename)
        bools = (True, False)
    elif file_format in ("dta", "dta.gz"):
        df = pandas.read_stata(filename)
        bools = (0, 1)
    else:
        assert False, f"Unhandled format: {file_format}"

    # Check we've got at least some of each value
    counts = df.has_event.value_counts()
    assert counts[bools[0]] > 10
    assert counts[bools[1]] > 10


@pytest.mark.parametrize(
    "inconsistent_date_formats,expect_error,error_match",
    [
        ({}, False, ""),
        ({"date_1": "YYYY-MM"}, True, "'date_1' has 'YYYY-MM'"),
        ({"date_2": "YYYY-MM"}, True, "'date_2' has format 'YYYY-MM'"),
        ({"date_3": "YYYY-MM"}, True, "'date_3' has 'YYYY-MM'"),
        ({"date_4": "YYYY-MM"}, True, "'date_4' has format 'YYYY-MM'"),
        ({"date_5": "YYYY-MM"}, True, "'date_5' has 'YYYY-MM'"),
        ({"date_6": "YYYY-MM"}, True, "'date_6' has format 'YYYY-MM'"),
    ],
)
def test_nested_aggregate_date_format_validation(
    inconsistent_date_formats, expect_error, error_match
):
    """Test that inconsistent date formats can be detected and reported in nested aggregated dates"""

    def study():
        return StudyDefinition(
            default_expectations={
                "rate": "exponential_increase",
                "incidence": 0.2,
                "date": {"earliest": "1900-01-01", "latest": "today"},
            },
            population=patients.all(),
            date_1=patients.with_these_clinical_events(
                codelist(["A"], system="ctv3"),
                returning="date",
                date_format=inconsistent_date_formats.get("date_1", "YYYY-MM-DD"),
            ),
            first_min_date=patients.minimum_of(
                "date_1",
                date_2=patients.with_these_clinical_events(
                    codelist(["B"], system="ctv3"),
                    returning="date",
                    date_format=inconsistent_date_formats.get("date_2", "YYYY-MM-DD"),
                ),
            ),
            second_min_date=patients.minimum_of(
                date_3=patients.with_these_clinical_events(
                    codelist(["Y"], system="ctv3"),
                    returning="date",
                    date_format=inconsistent_date_formats.get("date_3", "YYYY-MM-DD"),
                ),
                date_4=patients.with_these_clinical_events(
                    codelist(["Z"], system="ctv3"),
                    returning="date",
                    date_format=inconsistent_date_formats.get("date_4", "YYYY-MM-DD"),
                ),
            ),
            third_min_date=patients.minimum_of(
                date_5=patients.with_these_clinical_events(
                    codelist(["Y"], system="ctv3"),
                    returning="date",
                    date_format=inconsistent_date_formats.get("date_5", "YYYY-MM-DD"),
                ),
                date_6=patients.with_these_clinical_events(
                    codelist(["Z"], system="ctv3"),
                    returning="date",
                    date_format=inconsistent_date_formats.get("date_6", "YYYY-MM-DD"),
                ),
            ),
            min_of_second_and_third=patients.minimum_of(
                "second_min_date", "third_min_date"
            ),
            min_overall=patients.minimum_of(
                "min_of_second_and_third", "first_min_date"
            ),
            min_date_1_third_min=patients.minimum_of("date_1", "third_min_date"),
        )

    if expect_error:
        with pytest.raises(ValueError, match=error_match):
            study()
    else:
        study()


@pytest.mark.parametrize(
    "returning,date_filter_column,on_or_after,error,error_msg",
    [
        # invalid return value with no matching type
        ("foo", None, None, ValueError, "No matching type for 'foo'"),
        # invalid ONS_CIS column
        (
            "primary_diagnosis",
            None,
            None,
            TypeError,
            "returning=primary_diagnosis is not a valid ONS_CIS column",
        ),
        # invalid date_filter_column
        (
            "age_at_visit",
            "foo",
            None,
            TypeError,
            "date_filter_column=foo is not a valid ONS_CIS column",
        ),
        # invalid type of date_filter_column
        (
            "age_at_visit",
            "age_at_visit",
            None,
            TypeError,
            "date_filter_column=age_at_visit is type int, not a date",
        ),
        # date_filter_column required
        (
            "age_at_visit",
            None,
            None,
            ValueError,
            "date_filter_column is required",
        ),
        # date_filter_column required for number_of_matches_in_period when
        # date arg is specified
        (
            "number_of_matches_in_period",
            None,
            "2022-01-01",
            ValueError,
            "date_filter_column is required",
        ),
        # date_filter_column not required if returning is number_of_matches_in_period
        # and no date arg
        (
            "number_of_matches_in_period",
            None,
            None,
            None,
            None,
        ),
    ],
)
def test_ons_cis_study_definition_errors(
    returning, date_filter_column, on_or_after, error, error_msg
):
    def define_study():
        StudyDefinition(
            population=patients.all(),
            # by default returns last match in period, using visit date
            value=patients.with_an_ons_cis_record(
                returning=returning,
                date_filter_column=date_filter_column,
                on_or_after=on_or_after,
            ),
        )

    if error is None:
        # instantiating study definition raises no exceptions
        define_study()
    else:
        with pytest.raises(error, match=error_msg):
            define_study()
